{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Source\n",
    "https://www.kaggle.com/datamunge/sign-language-mnist\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "In this project I am using a dataset that contains images (actually their grayscale pixel values); each image represents a certain letter from A to Y in the sign language.\n",
    "The dataset does not contain any data on J or Z letters, as those have **motion** involved\n",
    "when translated into sign language. Images are 28 by 28 pixels, and there are a total of 34627 of them in the dataset.\n",
    "\n",
    "If one is interested in learning more about this they can visit the following page where they can translate text into how it would look in the sign language:\n",
    "https://wecapable.com/tools/text-to-sign-language-converter/.\n",
    "\n",
    "\n",
    "### Motivation\n",
    "\n",
    "After doing some research on this topic, I did not find a lot of applications that would do the reverse, i.e. translate images of signs into what they mean in English. Therefore, I decided to utilize some image processing techniques along with different classification algorithms to accomplish this task, although only with digits for now.\n",
    "\n",
    "### Goal\n",
    "\n",
    "My goal in this project is to compare the accuracies on the test set of the following models:\n",
    "SVM, MLP, and CNN. I expect CNN to perform better than the two other models, as Convolutional Neural Networks have proved to be more efficient in image classification tasks. Another goal is to build some kind of majority-vote ensemble, where the decision of the model with the highest accuracy, will be \"vetoed\" if the other two models' predictions are the same and differ from that of the best performing model. I decided to go with this ensemble model instead of the usual majority-vote ensemble, due to - as will be seen below - low test accuracy of one of the models.\n",
    "\n",
    "### Tensorflow\n",
    "\n",
    "Note that this project uses tensorflow in order to build a CNN model; therefore, tensorflow\n",
    "needs to be installed using *pip* for example.\n",
    "\n",
    "## Preparing the Dataset\n",
    "\n",
    "Here, we take the csv files that contain train and test data for our application.\n",
    "Some basic imports of numpy and matplotlib.pyplot are also done and will be used along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Using a dataset with \n",
    "# Letters instead of Digits in Sign Language\n",
    "############################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## loading the csv file\n",
    "X_TRAIN = pd.read_csv('./sign_mnist_train.csv')\n",
    "X_TEST = pd.read_csv('./sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the feature matrices and target vectors\n",
    "\n",
    "We also adjust the target vectors so that all labels of 24 get the value of 9, to account\n",
    "for the missing J letter in the middle of the alphabet (the reason behind this was explained above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# NOTE: I am changing target value of 24 to 9\n",
    "# because the value 9 is skipped \n",
    "# in possible target values\n",
    "############################################\n",
    "\n",
    "## getting the target vector for training set\n",
    "target_train = X_TRAIN[\"label\"]\n",
    "target_train[target_train == 24] = 9\n",
    "target_train = target_train.to_numpy()\n",
    "\n",
    "## getting the feature matrix for training set\n",
    "feature_matrix_train = X_TRAIN.drop(\"label\", axis=1)\n",
    "feature_matrix_train = feature_matrix_train.to_numpy() / 255\n",
    "\n",
    "## getting the target vector for testing set\n",
    "target_test = X_TEST[\"label\"]\n",
    "target_test[target_test == 24] = 9\n",
    "target_test = target_test.to_numpy()\n",
    "\n",
    "## getting the feature matrix for testing set\n",
    "feature_matrix_test = X_TEST.drop(\"label\", axis=1)\n",
    "feature_matrix_test = feature_matrix_test.to_numpy() / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting familiar with a sample\n",
    "\n",
    "Here we take a single example feature vector that contains a flattened list of \n",
    "pixel grayscale values. We, then, reshape this vector into a 28x28 matrix to display it\n",
    "with the help of plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target of this example is:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################################\n",
    "# Taking a look at an example image\n",
    "############################################\n",
    "\n",
    "## Here I am also going to initialize a variable IMG_SIZE\n",
    "## which I 'll use later as well\n",
    "## it is just the number of pixels on each side of a square image\n",
    "IMG_SIZE = 28\n",
    "\n",
    "plt.imshow(feature_matrix_train[0].reshape((IMG_SIZE, IMG_SIZE)))\n",
    "\n",
    "print(\"The target of this example is: \", target_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the image below that example \n",
    "above corresponds to the letter D, i.e. 3, \n",
    "cause we start counting labels from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Because A - 0, B - 1, C - 2, and D - 3\n",
    "# We can conclude that the target of the above feature vector makes sense\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./amer_sign2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are importing SVC for the SVM model, PCA (Principal Component Analysis) for feature extraction, and other modules for building pipelines and assesing a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model imports - sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# for k-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Building a pipeline with SVM and PCA\n",
    "############################################\n",
    "\n",
    "pipe_svm = make_pipeline(PCA(n_components=50, random_state=1),\n",
    "                         SVC(kernel='rbf', C=10, gamma='scale', random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# features and targets are in the right format\n",
    "# so we don't change anything for those here\n",
    "############################################\n",
    "\n",
    "X_train = feature_matrix_train\n",
    "y_train = target_train\n",
    "\n",
    "X_test = feature_matrix_test\n",
    "y_test = target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am running a K-fold cross validation to tweak the regularization of the SVM model\n",
    ",and I got the highest accuracy when C=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [1.         1.         1.         1.         0.99963583 1.\n",
      " 1.         1.         1.         1.        ]\n",
      "CV accuracy: 1.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# K fold cross validation (k = 10)\n",
    "############################################\n",
    "\n",
    "scores_svm = cross_val_score(estimator=pipe_svm,\n",
    "                          X=X_train,\n",
    "                          y=y_train,\n",
    "                          cv=10,\n",
    "                          n_jobs=-1) ## using all CPUs\n",
    "print('CV accuracy scores: %s' % scores_svm)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_svm), np.std(scores_svm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=50, random_state=1)),\n",
       "                ('svc', SVC(C=10, random_state=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting the model with the training data\n",
    "\n",
    "pipe_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8784160624651423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_svm = pipe_svm.predict(X_test)\n",
    "\n",
    "print(\"accuracy: \" + str(accuracy_score(y_test, y_pred_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model is somewhat overfitting the data, as observed from the discrepancy between the validation and test accuracy scores. Nevertheless, as we 'll see a bit later, this result is actually good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are using a Convolution Neural Network for image classification, we need to reshape our feature matrices so that they have the following final shapes (# of examples, 28 ,28, 1) - where the last dimension is 1 as we are using grayscale pixel values.\n",
    "\n",
    "Following this we join targets with feature matrices in tensorflow Datasets and batch them. (done for the test set a bit later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "############################################\n",
    "# getting the data into the right shape\n",
    "############################################\n",
    "\n",
    "# feature matrices have to be adjusted\n",
    "# removed ONE from dim\n",
    "X_train_cnn = feature_matrix_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "X_validation_cnn = X_train_cnn[:2746]\n",
    "X_train_cnn = X_train_cnn[2746:]\n",
    "\n",
    "X_test_cnn = feature_matrix_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# target vectors are unchanged\n",
    "y_train_cnn = target_train\n",
    "\n",
    "y_validation_cnn = y_train_cnn[:2746]\n",
    "y_train_cnn = y_train_cnn[2746:]\n",
    "\n",
    "y_test_cnn = target_test\n",
    "\n",
    "## putting everything into a Tensorflow Dataset\n",
    "X_train_cnn_new = tf.data.Dataset.from_tensor_slices((X_train_cnn, y_train_cnn))\n",
    "X_train_cnn_new = X_train_cnn_new.batch(32)\n",
    "\n",
    "validation_cnn_new = tf.data.Dataset.from_tensor_slices((X_validation_cnn, y_validation_cnn))\n",
    "validation_cnn_new = validation_cnn_new.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that above we are also creating a validation set from the ten percent of the training set\n",
    "\n",
    "Now, we are creating a Sequantial model using Keras, which is a wrapper around he Tensorflow,\n",
    "and we add layers to this model.\n",
    "\n",
    "The first three layers include Convolutional 2D and Max Pooling layers.\n",
    "Following this we flatten the input into two more \"dense\" layers.\n",
    "Only the last layer has softmax activation units (to get probability values in an OvR kind of sense).\n",
    "All other layers have Rectified Linear Unit activation functions which have proved to lead to better results in CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       32384     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 112,176\n",
      "Trainable params: 112,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "#### initialize a sequential model\n",
    "cnn = models.Sequential()\n",
    "\n",
    "#### 1st convolutional and pooling layers\n",
    "#### Note: the input size is (28, 28, 1)\n",
    "cnn.add(layers.Conv2D(filters=IMG_SIZE, kernel_size=(3, 3),\n",
    "                          activation='relu',\n",
    "                          input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "cnn.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#### 2nd convolutional and pooling layers\n",
    "\n",
    "cnn.add(layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                          activation='relu'))\n",
    "\n",
    "cnn.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#### 3rd convolutional and pooling layers\n",
    "cnn.add(layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                          activation='relu'))\n",
    "cnn.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flattening layer here, as no more Conv2D layers\n",
    "cnn.add(layers.Flatten())\n",
    "\n",
    "# dense layers\n",
    "cnn.add(layers.Dense(units=64, activation='relu'))\n",
    "cnn.add(layers.Dense(units=24, activation='softmax'))\n",
    "\n",
    "# print the summary of the model\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the build operation on CNN model\n",
    "tf.random.set_seed(13)\n",
    "cnn.build(input_shape=(None, IMG_SIZE, IMG_SIZE, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using the Adam optimizer which will adjust the regularization parameters by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model to tensorflow from keras\n",
    "cnn.compile(optimizer='adam', \n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are fitting the model by putting the the tensorflow Dataset we created earlier and letting the model train over 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "773/773 [==============================] - 9s 11ms/step - loss: 1.5327 - sparse_categorical_accuracy: 0.5128 - val_loss: 0.5984 - val_sparse_categorical_accuracy: 0.8044\n",
      "Epoch 2/5\n",
      "773/773 [==============================] - 9s 12ms/step - loss: 0.4102 - sparse_categorical_accuracy: 0.8643 - val_loss: 0.2148 - val_sparse_categorical_accuracy: 0.9421\n",
      "Epoch 3/5\n",
      "773/773 [==============================] - 9s 12ms/step - loss: 0.1400 - sparse_categorical_accuracy: 0.9624 - val_loss: 0.0579 - val_sparse_categorical_accuracy: 0.9920\n",
      "Epoch 4/5\n",
      "773/773 [==============================] - 11s 14ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.0249 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 5/5\n",
      "773/773 [==============================] - 10s 13ms/step - loss: 0.0264 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.0129 - val_sparse_categorical_accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab52d97940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "# Fitting\n",
    "####################\n",
    "cnn.fit(X_train_cnn_new, validation_data=validation_cnn_new, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see it looks like our model has the maximum accuracy on the validation set\n",
    "So now, let's actually see what the accuracy is on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.8830\n",
      "----------------\n",
      "Test Loss: \n",
      "0.4315030574798584\n",
      "----------------\n",
      "Test Accuracy: \n",
      "0.8830173015594482\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Evaluation of the Test Set\n",
    "##############################\n",
    "\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((X_test_cnn, y_test_cnn)).batch(32)\n",
    "\n",
    "\n",
    "loss, accuracy = cnn.evaluate(testing_dataset, verbose=1)\n",
    "\n",
    "print(\"----------------\")\n",
    "print(\"Test Loss: \")\n",
    "print(loss)\n",
    "print(\"----------------\")\n",
    "print(\"Test Accuracy: \")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get something similar to what we had with the SVM model, where the Test Accuracy is not well predicted by the Validation Accuracy score.\n",
    "\n",
    "An explanation to this could be that the dataset that I took from the source given at the top of the notebook is itself already divided into a test and a training sets, which means that they might end up having some general differences in them; and this might evetually lead to some overfitting of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's test the MultiLayer Perceptron model. Note MLP model was also tested in the Prototype assignment, although without Principal Component Analysis. (it performed poorly due to a large number of features)\n",
    "\n",
    "Here we create a pipeline from PCA and the MLPClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Building the MLP and PCA pipe\n",
    "##################################\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "pipe_mlp = make_pipeline(PCA(n_components=100, random_state=1),\n",
    "                         MLPClassifier(solver='adam', \n",
    "                                       alpha=1e-5, \n",
    "                                       hidden_layer_sizes=(100, 100, 50), \n",
    "                                       random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the MLPClassifier requires targets to be one hot encoded, we need to adapt our target vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Getting the data into the right\n",
    "# format by making targets one hot encoded\n",
    "##########################################\n",
    "\n",
    "y_list = y_train_cnn.tolist()\n",
    "y_list_validation = y_validation_cnn.tolist()\n",
    "y_list_test = y_test_cnn.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(y_list):\n",
    "    y_list[i] = np.zeros(24)\n",
    "    y_list[i][label] = 1\n",
    "\n",
    "for i, label in enumerate(y_list_test):\n",
    "    y_list_test[i] = np.zeros(24)\n",
    "    y_list_test[i][label] = 1\n",
    "    \n",
    "for i, label in enumerate(y_list_validation):\n",
    "    y_list_validation[i] = np.zeros(24)\n",
    "    y_list_validation[i][label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## targets in the right format\n",
    "y_train_mlp = np.array(y_list)\n",
    "y_validation_mlp = np.array(y_list_validation)\n",
    "y_test_mlp = np.array(y_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=100, random_state=1)),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=1e-05, hidden_layer_sizes=(100, 100, 50),\n",
       "                               random_state=1))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "# Fitting\n",
    "####################\n",
    "pipe_mlp.fit(X_train_cnn.reshape(-1, IMG_SIZE * IMG_SIZE), y_train_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Evaluation of the Validation Set\n",
    "##############################\n",
    "\n",
    "y_valid_mlp_pred = pipe_mlp.predict(X_validation_cnn.reshape(-1, IMG_SIZE * IMG_SIZE))\n",
    "\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_validation_mlp, y_valid_mlp_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6466815393195762\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# Evaluation of the Test Set\n",
    "##############################\n",
    "\n",
    "y_pred_mlp = pipe_mlp.predict(X_test)\n",
    "\n",
    "print(\"Validation accuracy: \" + str(accuracy_score(y_test_mlp, y_pred_mlp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude here that CNN and SVM perform better than the MLP model for this dataset. Moreover, the fact that, in the case of MLP, we also observe overfitting, further supports the claim I made above after seeing the discrepancy between Validation and Training Accuracies of SVM and CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Majority Vote Ensemble Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am performing several operations on the predicted target vectors from the three models above to estimate if the ensemble model I mentioned in the intro section would improve the accuracy we saw from SVM and CNN.\n",
    "\n",
    "Thus, if the predicted labels of SVM and MLP match and are different from that of CNN, then the ensemble \"votes\" for the SVM/MLP label. Otherwise, we go for CNN's predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# Building my own Majority Vote Ensemble \n",
    "# For accuracy prediction of the test data\n",
    "###############################################\n",
    "\n",
    "def predict_majority_vote_accuracy():\n",
    "    cnn_pred = np.argmax(cnn.predict(testing_dataset), axis=1)\n",
    "    svm_pred = pipe_svm.predict(X_test)\n",
    "    mlp_pred = np.argmax(pipe_mlp.predict(X_test), axis=1)\n",
    "    \n",
    "    set_pred = np.vstack((cnn_pred, svm_pred, mlp_pred)).tolist()\n",
    "    \n",
    "    vote_pred = []\n",
    "    \n",
    "    for i in range(cnn_pred.size):\n",
    "        toAppend = set_pred[0][i]\n",
    "        if set_pred[1][i] == set_pred[2][i]:\n",
    "            toAppend = set_pred[1][i]\n",
    "        vote_pred.append(toAppend)\n",
    "        \n",
    "    final_vote = np.array(vote_pred)\n",
    "    print(\"accuracy: \" + str(accuracy_score(y_test, final_vote)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8824595649749024\n"
     ]
    }
   ],
   "source": [
    "predict_majority_vote_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the estimate of the testing accuracy of this ensemble is slightly higher than those of SVM and CNN, the difference is really insignificant. Therefore, one might just use CNN (in practice, if we have larger feature vectors than here, we should expect the accuracy of SVM to decrease relative to CNN) for an application where we want to translate sign language into English, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that can be done to actually fully develop such an application would be to introduce object and motion detection to be able to locate a hand in an image with more objects around it and to enable the translation of signs that involve motion, e.g. letters I and Z, as was mentioned in the introduction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
